{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*1. Project Idea / Purpose\n",
    "\n",
    "Title: Comparing chess games between humans only and chess games between humans and engines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9uWZXH9LwoQg"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LO5] Streaming from https://database.lichess.org/standard/lichess_db_standard_rated_2025-09.pgn.zst (will stop once 300 human and 300 mixed games collected)...\n",
      "  collected total=50 (human=50, mixed=0)\n",
      "  collected total=100 (human=100, mixed=0)\n",
      "  collected total=150 (human=149, mixed=1)\n",
      "  collected total=200 (human=198, mixed=2)\n",
      "  collected total=250 (human=248, mixed=2)\n",
      "  collected total=300 (human=298, mixed=2)\n",
      "  collected total=350 (human=300, mixed=50)\n",
      "  collected total=400 (human=300, mixed=100)\n",
      "  collected total=450 (human=300, mixed=150)\n",
      "  collected total=500 (human=300, mixed=200)\n",
      "  collected total=550 (human=300, mixed=250)\n",
      "  collected total=600 (human=300, mixed=300)\n",
      "[LO5] Streaming complete. Collected 300 human and 300 mixed games (total 600)\n",
      "[LO5] Dataframe shape: (600, 10)\n",
      "[LO10] Saved dataset to data/lichess_human_mixed_sample.csv\n",
      "\n",
      "[LO1] Descriptive statistics (num_moves, avg_legal_moves, check_ratio, capture_ratio):\n",
      "                 count       mean        std        50%\n",
      "num_moves        600.0  71.433333  39.440565  65.000000\n",
      "avg_legal_moves  600.0  30.297819   4.881744  31.079502\n",
      "check_ratio      600.0   0.058003   0.047781   0.050000\n",
      "capture_ratio    600.0   0.233838   0.067574   0.235533\n",
      "[LO8] Saved figures\\box_num_moves.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshu\\AppData\\Local\\Temp\\ipykernel_7656\\2191332303.py:209: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.boxplot(x=\"label\", y=feat, data=df, palette=\"Set2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LO8] Saved figures\\hist_num_moves.png\n",
      "[LO8] Saved figures\\box_avg_legal_moves.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshu\\AppData\\Local\\Temp\\ipykernel_7656\\2191332303.py:209: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.boxplot(x=\"label\", y=feat, data=df, palette=\"Set2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LO8] Saved figures\\hist_avg_legal_moves.png\n",
      "[LO8] Saved figures\\box_check_ratio.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshu\\AppData\\Local\\Temp\\ipykernel_7656\\2191332303.py:209: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.boxplot(x=\"label\", y=feat, data=df, palette=\"Set2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LO8] Saved figures\\hist_check_ratio.png\n",
      "[LO8] Saved figures\\box_capture_ratio.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshu\\AppData\\Local\\Temp\\ipykernel_7656\\2191332303.py:209: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.boxplot(x=\"label\", y=feat, data=df, palette=\"Set2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LO8] Saved figures\\hist_capture_ratio.png\n",
      "\n",
      "[LO1] Hypothesis tests (Human vs Human) vs (Human vs Engine):\n",
      " - num_moves: Mann-Whitney U, stat=38609.0000, p=0.00261 => SIGNIFICANT\n",
      " - avg_legal_moves: Mann-Whitney U, stat=46534.5000, p=0.47 => not significant\n",
      " - check_ratio: Mann-Whitney U, stat=42879.0000, p=0.3169 => not significant\n",
      " - capture_ratio: Mann-Whitney U, stat=49294.0000, p=0.04314 => SIGNIFICANT\n",
      "\n",
      "[LO3] Clustering results (counts per label per cluster):\n",
      "label    Human vs Engine (mixed)  Human vs Human (likely)\n",
      "cluster                                                  \n",
      "0                            210                      246\n",
      "1                             90                       54\n",
      "\n",
      "[LO2] Classification dataset class counts: {0: 300, 1: 300}\n",
      "\n",
      "[LO2] Classification report (RandomForest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4747    0.5222    0.4974        90\n",
      "           1     0.4691    0.4222    0.4444        90\n",
      "\n",
      "    accuracy                         0.4722       180\n",
      "   macro avg     0.4719    0.4722    0.4709       180\n",
      "weighted avg     0.4719    0.4722    0.4709       180\n",
      "\n",
      "Confusion matrix:\n",
      " [[47 43]\n",
      " [52 38]]\n",
      "AUC: 0.4966\n",
      "\n",
      "Feature importances:\n",
      " avg_legal_moves    0.274594\n",
      "capture_ratio      0.261882\n",
      "num_moves          0.258442\n",
      "check_ratio        0.205082\n",
      "dtype: float64\n",
      "\n",
      "[LO6] Ethics & data governance\n",
      "\n",
      "    - Source: Lichess public database (publicly available PGN archives).\n",
      "    - No personal data used: usernames are pseudonyms; nonetheless we treat them respectfully.\n",
      "    - Labeling is heuristic (by username contains 'stockfish'/'bot' etc.) -> not definitive detection of cheating.\n",
      "    - This project is exploratory; any production use for enforcement would require robust verification and privacy review.\n",
      "    \n",
      "\n",
      "[LO4] AI assistance: This analysis design and code structure were iteratively improved using generative AI suggestions (document in README).\n",
      "\n",
      "[LO9] Application areas: Online fair-play detection, platform moderation, chess education analytics.\n",
      "\n",
      "[LO10/LO11] Next steps (document these in README):\n",
      "\n",
      "    - Extend features (centipawn loss using Stockfish analysis per move).\n",
      "    - Use temporal features, opening classification, Elo changes.\n",
      "    - Build Streamlit dashboard (visual interactive UI).\n",
      "    - Improve engine-detection heuristics; validate with known engine-labeled datasets.\n",
      "    - Use more months of lichess data and scale training data properly.\n",
      "    \n",
      "\n",
      "=== PIPELINE COMPLETE (LO1-LO11 covered with artifacts) ===\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# Capstone: Human vs Engine Chess Analysis (LO1 - LO11)\n",
    "# Single script that:\n",
    "# - Streams a Lichess .pgn.zst archive (stops early when enough games)\n",
    "# - Extracts features, labels games (human vs human / mixed)\n",
    "# - Saves CSVs, performs EDA, hypothesis tests, clustering, classification\n",
    "# - Sections are labelled by Learning Outcome (LO)\n",
    "# Author: Joshua Tutin (template)\n",
    "# =====================================================\n",
    "\n",
    "import os\n",
    "import io\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "# Data & analysis libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Try import zstandard (needed for .zst streaming)\n",
    "try:\n",
    "    import zstandard as zstd\n",
    "except Exception as e:\n",
    "    zstd = None\n",
    "\n",
    "# Try import python-chess\n",
    "try:\n",
    "    import chess\n",
    "    import chess.pgn\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"This script requires python-chess. Install with `pip install python-chess`\") from e\n",
    "\n",
    "# -----------------------------\n",
    "# Configurable parameters\n",
    "# -----------------------------\n",
    "LICHESS_URL = \"https://database.lichess.org/standard/lichess_db_standard_rated_2025-09.pgn.zst\"\n",
    "# If you want a different month change above URL.\n",
    "MAX_HUMAN_GAMES = 300       # target human vs human (likely)\n",
    "MAX_MIXED_GAMES = 300       # target human vs engine (mixed)\n",
    "MAX_TOTAL = MAX_HUMAN_GAMES + MAX_MIXED_GAMES\n",
    "OUTPUT_CSV = \"data/lichess_human_mixed_sample.csv\"\n",
    "DOWNLOAD_CHUNK = 1024 * 1024  # 1MB\n",
    "VERBOSE = True\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers\n",
    "# -----------------------------\n",
    "def info(msg):\n",
    "    if VERBOSE:\n",
    "        print(msg)\n",
    "\n",
    "# Heuristic engine detection terms (extendable)\n",
    "ENGINE_TERMS = [\n",
    "    \"stockfish\", \"engine\", \"lichess_bot\", \"lichess\", \"bot\", \"komodo\", \"fire\", \"shredder\",\n",
    "    \"stockfish\", \"crafty\", \"stockfxh\", \"lc0\", \"leela\", \"fairy\"\n",
    "]\n",
    "\n",
    "def is_engine_name(name: str) -> bool:\n",
    "    if not name:\n",
    "        return False\n",
    "    name_l = name.lower()\n",
    "    # direct match heuristics\n",
    "    for t in ENGINE_TERMS:\n",
    "        if t in name_l:\n",
    "            return True\n",
    "    # some engine accounts include digits/engine suffixes; simple heuristic:\n",
    "    if name_l.endswith(\"bot\") or \"engine\" in name_l:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# -----------------------------\n",
    "# LO5: Data collection & management\n",
    "# - Stream a lichess .pgn.zst file and parse games until targets met\n",
    "# - Saves raw CSV. (LO5: storage and processing)\n",
    "# -----------------------------\n",
    "def stream_collect_lichess_sample(url: str,\n",
    "                                 max_human: int,\n",
    "                                 max_mixed: int,\n",
    "                                 zst_file: str = None):\n",
    "    \"\"\"\n",
    "    Streams the lichess .pgn.zst archive and collects games until we have enough labelled samples.\n",
    "    Returns a list of records (dict).\n",
    "    If zstandard isn't installed, raises an error.\n",
    "    \"\"\"\n",
    "    if zstd is None:\n",
    "        raise RuntimeError(\"zstandard not available. Install with `pip install zstandard` to stream .zst files.\")\n",
    "\n",
    "    records_human = []\n",
    "    records_mixed = []\n",
    "\n",
    "    # Stream the remote URL and give the decompressor a streaming reader\n",
    "    info(f\"[LO5] Streaming from {url} (will stop once {max_human} human and {max_mixed} mixed games collected)...\")\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        dctx = zstd.ZstdDecompressor()\n",
    "        # Create a streaming reader that reads from the requests raw stream\n",
    "        with dctx.stream_reader(r.raw) as reader:\n",
    "            text_stream = io.TextIOWrapper(reader, encoding=\"utf-8\", errors=\"ignore\", newline=\"\\n\")\n",
    "            # Read PGN games one by one\n",
    "            count = 0\n",
    "            while True:\n",
    "                if len(records_human) >= max_human and len(records_mixed) >= max_mixed:\n",
    "                    break\n",
    "                game = chess.pgn.read_game(text_stream)\n",
    "                if game is None:\n",
    "                    break  # end of file\n",
    "                count += 1\n",
    "\n",
    "                # Skip games with missing headers or extremely short games\n",
    "                white = game.headers.get(\"White\", \"\").strip()\n",
    "                black = game.headers.get(\"Black\", \"\").strip()\n",
    "                result = game.headers.get(\"Result\", \"\")\n",
    "                if not white and not black:\n",
    "                    continue\n",
    "\n",
    "                # Heuristic labelling\n",
    "                white_engine = is_engine_name(white)\n",
    "                black_engine = is_engine_name(black)\n",
    "\n",
    "                # Skip pure engine vs engine games (we want human or mixed)\n",
    "                if white_engine and black_engine:\n",
    "                    continue\n",
    "\n",
    "                label = \"Human vs Engine (mixed)\" if (white_engine or black_engine) else \"Human vs Human (likely)\"\n",
    "\n",
    "                # don't exceed targets\n",
    "                if label == \"Human vs Human (likely)\" and len(records_human) >= max_human:\n",
    "                    continue\n",
    "                if label == \"Human vs Engine (mixed)\" and len(records_mixed) >= max_mixed:\n",
    "                    continue\n",
    "\n",
    "                # Extract features\n",
    "                board = game.board()\n",
    "                num_moves = 0\n",
    "                checks = 0\n",
    "                captures = 0\n",
    "                legal_counts = []  # legal moves counts per ply\n",
    "\n",
    "                # iterate moves; we will capture legal moves count BEFORE the move (branching factor)\n",
    "                for mv in game.mainline_moves():\n",
    "                    legal_before = list(board.legal_moves)\n",
    "                    legal_counts.append(len(legal_before))\n",
    "                    # check/capture before pushing?\n",
    "                    if board.is_check():\n",
    "                        checks += 1\n",
    "                    if board.is_capture(mv):\n",
    "                        captures += 1\n",
    "                    board.push(mv)\n",
    "                    num_moves += 1\n",
    "\n",
    "                avg_legal_moves = float(np.mean(legal_counts)) if legal_counts else 0.0\n",
    "                # record\n",
    "                rec = {\n",
    "                    \"white\": white,\n",
    "                    \"black\": black,\n",
    "                    \"result\": result,\n",
    "                    \"label\": label,\n",
    "                    \"num_moves\": num_moves,\n",
    "                    \"checks\": checks,\n",
    "                    \"captures\": captures,\n",
    "                    \"avg_legal_moves\": avg_legal_moves,\n",
    "                    \"check_ratio\": checks / num_moves if num_moves>0 else 0.0,\n",
    "                    \"capture_ratio\": captures / num_moves if num_moves>0 else 0.0\n",
    "                }\n",
    "\n",
    "                if label == \"Human vs Human (likely)\":\n",
    "                    records_human.append(rec)\n",
    "                else:\n",
    "                    records_mixed.append(rec)\n",
    "\n",
    "                if (len(records_human) + len(records_mixed)) % 50 == 0:\n",
    "                    info(f\"  collected total={len(records_human)+len(records_mixed)} (human={len(records_human)}, mixed={len(records_mixed)})\")\n",
    "\n",
    "    # combine\n",
    "    combined = records_human + records_mixed\n",
    "    info(f\"[LO5] Streaming complete. Collected {len(records_human)} human and {len(records_mixed)} mixed games (total {len(combined)})\")\n",
    "    return combined\n",
    "\n",
    "# -----------------------------\n",
    "# LO1 & LO2: Basic stats & data manipulation examples\n",
    "# - We'll compute descriptive stats and illustrate mean/median/std\n",
    "# -----------------------------\n",
    "def descriptive_statistics(df: pd.DataFrame):\n",
    "    info(\"\\n[LO1] Descriptive statistics (num_moves, avg_legal_moves, check_ratio, capture_ratio):\")\n",
    "    stats_df = df[[\"num_moves\", \"avg_legal_moves\", \"check_ratio\", \"capture_ratio\"]].describe().T\n",
    "    print(stats_df[['count','mean','std','50%']])\n",
    "    return stats_df\n",
    "\n",
    "# -----------------------------\n",
    "# LO2 & LO8: EDA plots (boxplots, histograms)\n",
    "# -----------------------------\n",
    "def exploratory_plots(df: pd.DataFrame, out_dir=\"figures\"):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    features = [\"num_moves\", \"avg_legal_moves\", \"check_ratio\", \"capture_ratio\"]\n",
    "    for feat in features:\n",
    "        plt.figure(figsize=(8,5))\n",
    "        sns.boxplot(x=\"label\", y=feat, data=df, palette=\"Set2\")\n",
    "        plt.title(f\"Boxplot: {feat} by label\")\n",
    "        plt.tight_layout()\n",
    "        path = os.path.join(out_dir, f\"box_{feat}.png\")\n",
    "        plt.savefig(path)\n",
    "        info(f\"[LO8] Saved {path}\")\n",
    "        plt.close()\n",
    "\n",
    "        plt.figure(figsize=(8,5))\n",
    "        sns.histplot(data=df, x=feat, hue=\"label\", kde=True, element=\"step\", stat=\"density\")\n",
    "        plt.title(f\"Distribution: {feat} by label\")\n",
    "        plt.tight_layout()\n",
    "        path = os.path.join(out_dir, f\"hist_{feat}.png\")\n",
    "        plt.savefig(path)\n",
    "        info(f\"[LO8] Saved {path}\")\n",
    "        plt.close()\n",
    "\n",
    "# -----------------------------\n",
    "# LO1: Hypothesis testing\n",
    "# - Compare human vs human and human vs engine for selected metrics\n",
    "# -----------------------------\n",
    "def hypothesis_tests(df: pd.DataFrame):\n",
    "    # two groups\n",
    "    group_h = df[df.label == \"Human vs Human (likely)\"]\n",
    "    group_m = df[df.label == \"Human vs Engine (mixed)\"]\n",
    "\n",
    "    tests = {}\n",
    "    for feat in [\"num_moves\", \"avg_legal_moves\", \"check_ratio\", \"capture_ratio\"]:\n",
    "        x = group_h[feat].dropna()\n",
    "        y = group_m[feat].dropna()\n",
    "        # normality check (Shapiro) - small samples only; we'll use Mann-Whitney as robust fallback\n",
    "        # Use t-test if both look normal, otherwise Mann-Whitney U\n",
    "        use_ttest = False\n",
    "        try:\n",
    "            if len(x) >= 8 and len(y) >= 8:\n",
    "                psh_x = stats.shapiro(x.sample(500) if len(x)>500 else x)[1]\n",
    "                psh_y = stats.shapiro(y.sample(500) if len(y)>500 else y)[1]\n",
    "                use_ttest = (psh_x > 0.05 and psh_y > 0.05)\n",
    "        except Exception:\n",
    "            use_ttest = False\n",
    "\n",
    "        if use_ttest:\n",
    "            stat, pval = stats.ttest_ind(x, y, equal_var=False)\n",
    "            test_name = \"t-test (indep)\"\n",
    "        else:\n",
    "            stat, pval = stats.mannwhitneyu(x, y, alternative='two-sided')\n",
    "            test_name = \"Mann-Whitney U\"\n",
    "\n",
    "        tests[feat] = {\"test\": test_name, \"stat\": float(stat), \"pval\": float(pval)}\n",
    "    info(\"\\n[LO1] Hypothesis tests (Human vs Human) vs (Human vs Engine):\")\n",
    "    for feat, res in tests.items():\n",
    "        sig = \"SIGNIFICANT\" if res[\"pval\"] < 0.05 else \"not significant\"\n",
    "        print(f\" - {feat}: {res['test']}, stat={res['stat']:.4f}, p={res['pval']:.4g} => {sig}\")\n",
    "    return tests\n",
    "\n",
    "# -----------------------------\n",
    "# LO3 & LO7: Clustering + visualization\n",
    "# -----------------------------\n",
    "def clustering_analysis(df: pd.DataFrame, n_clusters=2):\n",
    "    feats = [\"num_moves\", \"avg_legal_moves\", \"check_ratio\", \"capture_ratio\"]\n",
    "    X = df[feats].fillna(0).values\n",
    "    km = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "    clusters = km.fit_predict(X)\n",
    "    df[\"cluster\"] = clusters\n",
    "    cluster_counts = df.groupby([\"cluster\",\"label\"]).size().unstack(fill_value=0)\n",
    "    info(\"\\n[LO3] Clustering results (counts per label per cluster):\")\n",
    "    print(cluster_counts)\n",
    "    return km, df\n",
    "\n",
    "# -----------------------------\n",
    "# LO2 & LO4: Classification (Simple model)\n",
    "# - RandomForest to try to predict label (human vs mixed)\n",
    "# -----------------------------\n",
    "def classification_task(df: pd.DataFrame):\n",
    "    # Prepare X,y\n",
    "    df2 = df.copy()\n",
    "    # only keep human vs mixed (we have these two labels)\n",
    "    df2 = df2[df2.label.isin([\"Human vs Human (likely)\", \"Human vs Engine (mixed)\"])]\n",
    "    df2[\"y\"] = (df2.label == \"Human vs Engine (mixed)\").astype(int)  # 1=mixed, 0=human\n",
    "    feats = [\"num_moves\", \"avg_legal_moves\", \"check_ratio\", \"capture_ratio\"]\n",
    "    X = df2[feats].fillna(0)\n",
    "    y = df2[\"y\"]\n",
    "\n",
    "    # Check class counts\n",
    "    counts = y.value_counts().to_dict()\n",
    "    info(f\"\\n[LO2] Classification dataset class counts: {counts}\")\n",
    "    # If any class has <2 examples, skip classifier\n",
    "    if y.nunique() < 2 or any(v < 2 for v in counts.values()):\n",
    "        info(\"[LO2] Not enough data to train classifier.\")\n",
    "        return None\n",
    "\n",
    "    # stratify only when possible\n",
    "    stratify = y if (min(counts.values()) >= 2) else None\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=stratify)\n",
    "    model = RandomForestClassifier(n_estimators=150, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    proba = model.predict_proba(X_test)[:,1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "    info(\"\\n[LO2] Classification report (RandomForest):\")\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion matrix:\\n\", cm)\n",
    "    if proba is not None and len(np.unique(y_test))>1:\n",
    "        try:\n",
    "            auc = roc_auc_score(y_test, proba)\n",
    "            print(f\"AUC: {auc:.4f}\")\n",
    "        except Exception:\n",
    "            pass\n",
    "    # feature importance\n",
    "    fi = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "    print(\"\\nFeature importances:\\n\", fi)\n",
    "    return model, fi\n",
    "\n",
    "# -----------------------------\n",
    "# LO6: Ethical considerations printed\n",
    "# -----------------------------\n",
    "def print_ethics_section():\n",
    "    info(\"\\n[LO6] Ethics & data governance\")\n",
    "    print(\"\"\"\n",
    "    - Source: Lichess public database (publicly available PGN archives).\n",
    "    - No personal data used: usernames are pseudonyms; nonetheless we treat them respectfully.\n",
    "    - Labeling is heuristic (by username contains 'stockfish'/'bot' etc.) -> not definitive detection of cheating.\n",
    "    - This project is exploratory; any production use for enforcement would require robust verification and privacy review.\n",
    "    \"\"\")\n",
    "\n",
    "# -----------------------------\n",
    "# LO10 & LO11: Save artifacts and provide next steps\n",
    "# -----------------------------\n",
    "def save_outputs(df: pd.DataFrame, csv_path=OUTPUT_CSV):\n",
    "    os.makedirs(os.path.dirname(csv_path) if os.path.dirname(csv_path) else \".\", exist_ok=True)\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    info(f\"[LO10] Saved dataset to {csv_path}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Main pipeline\n",
    "# -----------------------------\n",
    "def main_pipeline():\n",
    "    # Section: collect data (LO5)\n",
    "    try:\n",
    "        collected = stream_collect_lichess_sample(LICHESS_URL, MAX_HUMAN_GAMES, MAX_MIXED_GAMES)\n",
    "    except Exception as e:\n",
    "        info(f\"[ERROR] Data streaming failed: {e}\")\n",
    "        info(\"You can download the lichess .pgn.zst manually and set LICHESS_URL to a local file or install zstandard.\")\n",
    "        return\n",
    "\n",
    "    if len(collected) == 0:\n",
    "        info(\"[WARN] No games collected. Check URL, internet, or zstandard availability.\")\n",
    "        return\n",
    "\n",
    "    df = pd.DataFrame(collected)\n",
    "    info(f\"[LO5] Dataframe shape: {df.shape}\")\n",
    "    # Save raw\n",
    "    save_outputs(df, OUTPUT_CSV)\n",
    "\n",
    "    # LO1 & LO2: descriptive stats\n",
    "    desc = descriptive_statistics(df)\n",
    "\n",
    "    # LO8: EDA plots\n",
    "    exploratory_plots(df)\n",
    "\n",
    "    # LO1: hypothesis tests\n",
    "    tests = hypothesis_tests(df)\n",
    "\n",
    "    # LO3 & LO7: clustering\n",
    "    km, df = clustering_analysis(df, n_clusters=2)\n",
    "\n",
    "    # LO2: classification\n",
    "    clfres = classification_task(df)\n",
    "\n",
    "    # LO6: ethics\n",
    "    print_ethics_section()\n",
    "\n",
    "    # LO4: show how AI was used (we'll document; user should include AI assistance notes in README)\n",
    "    info(\"\\n[LO4] AI assistance: This analysis design and code structure were iteratively improved using generative AI suggestions (document in README).\")\n",
    "\n",
    "    # LO9: applications (print short note)\n",
    "    info(\"\\n[LO9] Application areas: Online fair-play detection, platform moderation, chess education analytics.\")\n",
    "\n",
    "    # LO10 & LO11: plan & next steps\n",
    "    info(\"\\n[LO10/LO11] Next steps (document these in README):\")\n",
    "    print(\"\"\"\n",
    "    - Extend features (centipawn loss using Stockfish analysis per move).\n",
    "    - Use temporal features, opening classification, Elo changes.\n",
    "    - Build Streamlit dashboard (visual interactive UI).\n",
    "    - Improve engine-detection heuristics; validate with known engine-labeled datasets.\n",
    "    - Use more months of lichess data and scale training data properly.\n",
    "    \"\"\")\n",
    "\n",
    "    info(\"\\n=== PIPELINE COMPLETE (LO1-LO11 covered with artifacts) ===\")\n",
    "    return df\n",
    "\n",
    "# Run main pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    df_final = main_pipeline()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* You may add as many sections as you want, as long as it supports your project workflow.\n",
    "* All notebook's cells should be run top-down (you can't create a dynamic wherein a given point you need to go back to a previous cell to execute some task, like go back to a previous cell and refresh a variable content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ltNetd085qHf"
   },
   "source": [
    "# Push files to Repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In cases where you don't need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "aKlnIozA4eQO",
    "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.save_checkpoint();",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No changes detected by Git. Nothing to commit.\n",
      "Pushed to GitHub successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "from IPython.display import display, Javascript\n",
    "import ipynbname\n",
    "\n",
    "# 1. Save the notebook\n",
    "display(Javascript('IPython.notebook.save_checkpoint();'))\n",
    "\n",
    "# 2. Detect current notebook filename\n",
    "nb_path = ipynbname.path()\n",
    "notebook_name = str(nb_path.name)\n",
    "\n",
    "# 3. Load notebook JSON\n",
    "with open(notebook_name, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 4. Force a dummy change to ensure Git detects a difference\n",
    "# Adds a harmless comment to the first code cell\n",
    "if \"cells\" in data and len(data[\"cells\"]) > 0:\n",
    "    first_cell = data[\"cells\"][0]\n",
    "    if first_cell.get(\"cell_type\") == \"code\":\n",
    "        # Remove any previous dummy line to keep notebook clean\n",
    "        first_cell[\"source\"] = [line for line in first_cell[\"source\"] if \"# Auto-update: forced change\" not in line]\n",
    "        first_cell[\"source\"].append(\"\\n# Auto-update: forced change to trigger Git commit\\n\")\n",
    "\n",
    "# 5. Rewrite notebook JSON\n",
    "with open(notebook_name, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=1)\n",
    "\n",
    "# 6. Stage for Git\n",
    "subprocess.run([\"git\", \"add\", \"-f\", notebook_name], check=True)\n",
    "\n",
    "# 7. Commit changes\n",
    "try:\n",
    "    subprocess.run([\"git\", \"commit\", \"-m\", f\"Auto-update {notebook_name}\"], check=True)\n",
    "    print(f\"Committed changes to {notebook_name}.\")\n",
    "except subprocess.CalledProcessError:\n",
    "    print(\"No changes detected by Git. Nothing to commit.\")\n",
    "\n",
    "# 8. Push to GitHub\n",
    "subprocess.run([\"git\", \"push\", \"origin\", \"main\"], check=True)\n",
    "print(\"Pushed to GitHub successfully.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Data Practitioner Jupyter Notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
